{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5867d109518b4391af99e37046bd6e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='I want:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddff640006c486493c72b844f1237aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk.stem.porter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandasql import sqldf\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sentiment_module import sentiment_term, sentiment\n",
    "import collections\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "#nltk.download( 'stopwords' )\n",
    "\n",
    "\n",
    "# importing data from google sheets\n",
    "sheet_id = '15kPBQi8fW6EV2P1k0MPN0iRictK9Vg5AnEKVojkKsRQ'\n",
    "df = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv\")\n",
    "df['id'] = df.index + 1\n",
    "\n",
    "# creating two data frames to separate out the positive and negative reviews wiht the associated ID\n",
    "positive = df[['id', 'Name', 'Positive Review']]\n",
    "negative = df[['id', 'Name', 'Negative Review']]\n",
    "\n",
    "# test string\n",
    "test_pos = positive['Positive Review'][2]\n",
    "test_n = negative['Negative Review'][3]\n",
    "\n",
    "# function creation\n",
    "def clean(review): \n",
    "    stop_words = nltk.corpus.stopwords.words( 'english' )\n",
    "    term_list = []\n",
    "    review = str(review)\n",
    "    for term in review.split():\n",
    "        if term not in stop_words: \n",
    "            term = term.lower()\n",
    "            term_list.append(term)  # Append term to the list\n",
    "    return term_list  # Return the list after the loop finishes\n",
    "\n",
    "def get_sentiment(review): \n",
    "    sentiment_list = []\n",
    "    for term in review: \n",
    "        if sentiment.exist(term):\n",
    "            sent_term = sentiment.describe(term)\n",
    "            sentiment_list.append(sent_term)\n",
    "    return np.unique(sentiment_list)\n",
    "\n",
    "def get_overall_sentiment(review): \n",
    "    if sentiment.exist(review): \n",
    "        sentiment_overall = sentiment.describe(review)\n",
    "    return sentiment_overall\n",
    "\n",
    "def clean_title(title):\n",
    "    return re.sub(\"[^a-zA-Z0-9 ]\", \"\", title)\n",
    "\n",
    "def search(title): \n",
    "    title = clean_title(title)\n",
    "    query_vec = vectorizer.transform([title])\n",
    "    similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "    indicies = np.argpartition(similarity, -5)[-5:]\n",
    "    results = df.iloc[indicies]\n",
    "    return results[::-1]\n",
    "\n",
    "\n",
    "\n",
    "# Goal: find 5 words in each review (positive, negative) to describe the place \n",
    "# Remove stop words from term vectors\n",
    "\n",
    "positive_data = []\n",
    "negative_data = []\n",
    "for i in range(len(df)): \n",
    "    positive_review = get_overall_sentiment(clean(df['Positive Review'][i]))\n",
    "    positive_data.append(positive_review)\n",
    "\n",
    "    negative_review = get_overall_sentiment(clean(df['Negative Review'][i]))\n",
    "    negative_data.append(negative_review)\n",
    "\n",
    "p_df = pd.DataFrame(positive_data)\n",
    "n_df = pd.DataFrame(negative_data)\n",
    "\n",
    "p_df['id'] = df['id']\n",
    "n_df['id'] = df['id']\n",
    "\n",
    "p_df = p_df.rename(columns={'0': 'positive sentiment'}, inplace=True)\n",
    "n_df = n_df.rename(columns={'0': 'negative sentiment'}, inplace=True)\n",
    "\n",
    "df['Review'] = df['Positive Review'] + ' ' + df['Negative Review'] \n",
    "\n",
    "# cleaning the title of all the locations\n",
    "df['New Review'] = df['Review'].apply(clean_title)\n",
    "\n",
    "# creating a TFIDF matrix of word frequencies\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf = vectorizer.fit_transform(df['New Review'])\n",
    "\n",
    "def find_similar_locations(id): \n",
    "    similar_locations = df[(df['id'] == id) & (df['Rating'] > 2.5)][\"id\"].unique()\n",
    "    similar_locations_recs = df[(df['id'] == id) & (df['Rating'] > 2.5)][\"id\"]\n",
    "    # finding only the movies 10% or more of places I liked\n",
    "    similar_locations_recs = similar_locations_recs.value_counts() / len(similar_locations)\n",
    "    similar_locations_recs = similar_locations_recs[similar_locations_recs > 0.1]\n",
    "\n",
    "    all_me = df[(df['id'].isin(similar_locations_recs.index) & df['Rating'] > 2.5)]\n",
    "\n",
    "    # big differential locations are similar to the input locatioin instead of just similar to that location\n",
    "    all_me_recs = all_me['id'].value_counts()/len(all_me['id'].unique())\n",
    "\n",
    "    rec_percentages = pd.concat([similar_locations_recs, all_me_recs], axis=1)\n",
    "    rec_percentages.columns = [\"similar locations\", \"all locations\"]\n",
    "\n",
    "\n",
    "    # higher the score the better the recommendations is \n",
    "    rec_percentages['score'] = rec_percentages['similar locations']/rec_percentages['all locations']\n",
    "    rec_percentages = rec_percentages.sort_values(\"score\", ascending = False)\n",
    "\n",
    "    return rec_percentages.head(10).merge(df, left_index=True, right_on='id')\n",
    "\n",
    "\n",
    "input_name = widgets.Text(\n",
    "    value = \"\", \n",
    "    description = \"I want:\", \n",
    "    disabled = False\n",
    ")\n",
    "\n",
    "recommendation_list = widgets.Output()\n",
    "\n",
    "def on_type(data): \n",
    "    with recommendation_list:\n",
    "        recommendation_list.clear_output()\n",
    "        title = data['new']\n",
    "        if len(title) > 2:\n",
    "            results = search(title)\n",
    "            id = results.iloc[0]['id']\n",
    "            display(find_similar_locations(id))\n",
    "\n",
    "input_name.observe(on_type, names = 'value')\n",
    "display(input_name, recommendation_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSA_Grad_Py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
